// The generated lexer module will start with this code
{
open FSharp.Text.Lexing
open System
// open the module that defines the tokens
open CalculatorParser
// Set the language to English such that 4.0 is parsed as 4 and not 40.
System.Globalization.CultureInfo.CurrentCulture <- new System.Globalization.CultureInfo("en-US")
}

// We define macros for some regular expressions we will use later
let digit       = ['0'-'9']
let num         = digit+ ( '.' digit+)?  ('E' ('+'|'-')? digit+ )?
let whitespace  = [' ' '\t']
let newline     = "\n\r" | '\n' | '\r'

// We define now the rules for recognising and building tokens
// for each of the tokens of our language we need a rule
// NOTE: rules are applied in order top-down.
//       This is important when tokens overlap (not in this example)
rule tokenize = parse
// deal with tokens that need to be ignored (skip them)
| whitespace    { tokenize lexbuf }
| newline       { lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf; }
// deal with tokens that need to be built
| num           { NUM(Double.Parse(LexBuffer<_>.LexemeString lexbuf)) }
//variable goes here?       <--
| '*'           { TIMES }
| '/'           { DIV }
| '+'           { PLUS }
| '-'           { MINUS }
| '^'           { POW }
| '['			{ LSBRACK }
| ']'			{ RSBRACK }
//b operators
| 'true'		{ TRUE }
| 'false'       { FALSE }
| '&'			{ EAGERAND }
| '|'			{ EAGEROR }
| '&&'			{ SHORTAND } //do we need this?
| '||'			{ SHORTOR }
| '!'			{ NEG }
| '='			{ EQUAL }
| '!='			{ INEQUAL }
| '>'           { GREATER}
| '>='          { GEQUAL }
| '<'			{ LESSER }
| '<='			{ LEQUAL }
| '('           { LPAR }
| ')'           { RPAR }
//C operators
| ':='			{ ASSIGN }
| 'skip'        { SKIP }
| ';'			{ CLINE }
| 'if'          { IF }
| 'fi'          { FI }
| 'do'			{ DO }
| 'od'			{ OD }
//GC operators
/ '->'			{ FUNC }
/ '[]'			{ NSTAT }
| eof           { EOF }
